# Type grounded CUI

The objective of chatbots is to provide services to users through a conversational user interface. But what is service? In prevalent software development approaches, such as Service-Oriented Architecture (SOA) and its successors like microservices and cloud-native approaches, services are the basic building blocks. A service is a contract for a business capability and is entirely defined by its type, including its name, inputs, and outputs at the conceptual level, protocols and formats utilized to communicate with the service, and any other service-specific information or constraints at the implementation level. A well-defined service decouples its client from its provider, enabling software to be built independently and reused by different applications and systems.

From the perspective of the caller or client, a service can be viewed as a function, with its type being the corresponding type signature that defines its input and output. In this context, the goal of conversational user interface is to instantiate an object, or create an instance of some function type. This involves identifying the function by its name and recursively instantiating values for all its input parameters. This suggests a new, type-grounded way of building conversational user interface.

Building CUI in this type-grounded fashion means we always convert user utterances into data structures (known as semantic frames), we then follow interaction logic predefined by builder to generate dialog act, a structured representation of what bot need to communicate back to the user, and finally render such dialog act into natural text in a given language and style. The high-level goal of interaction logic is thus creating instances of types, often recursively, so that we can invoke desired function for user, and render the result back. The interaction logic is fully defined in the clean structured logic space (instead of messy natural language space), so it is very friendly to existing business application developers.  

In practice, the type-grounded CUI can be done in three layers. First, we declare the schema of the type, including its label, and input parameters for function type or member data for data type. Both input parameters or member data are commonly referred as slots, again specified by its label and type. Second, we can annotate each type with interaction logic, which defines in the structured semantic space, how to build instance of that type based on business conditions exposed via service APIs. Lastly, one add the language perception annotation exemplifying how to compute implied meaning from the utterance under context, and how to convert dialog acts (structured representation of meaning) back to natural text.

At schema level, type-grounded way of building CUI makes it natural to reuse the backend development, it comes with has many advantages.
1. API Schema provides natural boundary for both design and implementation. Given the set of APIs, it should be immediately clear whether given conversation is relevant or not. 
2. API schema typically is a result of careful deliberation between the product owner and software architect, so it is usually normalized to be minimal and orthogonal. This means the similar functionalities are generally serviced by the same APIs, so there is no need to create the equivalency between user intention at language level, as all we have to do it mapping language toward the APIs.
3. We can naturally separate the different concerns, so different people can work on the different aspects: the actual service can be implemented by the backend team, conversational user interface builder can take care of interaction logic, and CUI designer can provide the script for better user experience.

At interaction level, one of the major challenges of building a CUI is that the builder does not have control over what the user can express at any given turn. This can be problematic for all flow-based approaches, since the chatbot won't know what to respond if the current conversational path is not defined by the builder. If the CUI is defined in a type-grounded fashion, the chatbot only need to figure out which slot is missing value, or needs the instance of its type to be created, in order to eventually invoke a function that benefit both user and business. It does not matter what conversational path was followed to get to this state. This greatly reduce the cost of building an usable conversational user interface, as there is no need to enumerate exponentially growing number of conversational path for the chatbot to behave intelligent. This is the layer where business can inject their goal and strategy to make the conversation relevant for both user and business.

With business logic taken care of at interaction layer, the main responsibility left for language layer is translation from structured data to natural language back and forth. There are hopes that we can even automate this layer, to large extent.

## A proper type system
Building CUI in a type-grounded fashion, however, put a strict requirements on the type system we need to support. In programming languages, a type system is a logical system comprising a set of rules that assigns a property called a type to the various constructs of a computer program, such as variables, expressions, functions or modules. It is considered as a starting point for any programming language and everything else is built on top of this. The standard way of describing APIs nowadays is OpenAPI. OpenAPI is a programming language agnostic way to define functions, there is also a type system at this core. 

The core of the type system is to specify what types the programming language support. Types in programming languages are broadly classified and can be divided into built-in types represented by int and float, and abstract types represented by class and function. Since the types serve as the basis of the problem modeling, it is important to support modern concepts like: containers, inheritance and polymorphism, in addition to basic user defined data types if one wants to make is easier to model complex problems, which is exactly what [OpenAPI](https://swagger.io/docs/specification/data-models/) did.

While recently there are some effort of supporting composite data type out of necessity,conversation driven CUI approaches in general does not have explicit support for user defined type, container, and polymorphism. While it is possible to simulate conversational behavior of these type system features, doing so puts a burden on the CUI builder and greatly increase the cost of building good conversational experience. OpenCUI provides support for every type system features defined by OpenAPI 3.x at CUI level for both input and output, with the only exception on dictionary which only have output support. This way, so that OpenCUI builder can enjoy modeling the problem at the abstract level permitted by modern type system.

The types in OpenAPI are supported on OpenCUI as follows: functions are mapped to skill, classes are mapped to frame, and primitive type and enum are mapped to entity. This means that there is a one-to-one mapping between semantics from user utterance to data structure at programming language level. The conversational behavior for these type can be defined through some declarative annotation at both interaction level and language level. If defined in a library, these behaviors can be reused by other builders after importing.  

## Special considerations
Type-grounded CUI requires a entirely different thinking around conversational experience. For example, the conversations from bot's perspective should be structured instead of free flow, and context is really just stack of the type that still active.

### Structured conversations
Since the conversational behavior is defined on the frame, and frame is potentially nested, so conversational behavior are necessarily nested. To make sure we can fill the nested structure through conversations, we make a bot follow a simple strategy like depth first search. The conversation that follow such systematic algorithm is called structured conversation. 

Structured conversations are simply composite conversation sequences, in both sequential and nested sense. Each sequence has a concrete goal, and have a clear start and finish. Finish can come in different flavors: including abort by user or early exit per business logic. Furthermore, each sequence has a clear owner. An owner can start the sequence, and set the goal and communicate to the other party, and  other party is cooperating in help to achieve the goal for the owner. 

Current conversation owner can yield ownership to other party: for example, the bot can say "what can I do for you", this can potentially start a nested conversation sequence that is owned by a user. And after the sequence concludes, then the ownership automatically get back to the bot. Of course, in this case, a user can choose not to take the ownership by simply replying "nothing, thanks" , which will bring closure to bot's owned sequence. The bot is expected to simply close the sequence in the next turn. 

### Implicit Contextual Management
One of the hallmark of natural language is the same word can mean different things in the different context. While context dependent behavior is explicit modeled by conversation driven approaches, type grounded CUI naturally has a context, the stack of frame that represent the the current filling. This forest representation of dialog state in the type space made it easy to find the coreference for the pronouns and produce the contextual behavior almost as a by product.

## Conclusion
According to Gates, only two technologies have ever struck him as “revolutionary”: the first is the modern graphical user interface (GUI). With its easy to use, and gradually reduction of cost of building GUI application over the year, GUI application has forever changed human civilization. Now it is that time again, CUI has the potential of removing any barrier for any user to access any services. Furthermore, with the recent advance in foundation models, the barrier of building such experience is also largely gone, we expect any common sensical people with good understanding of business goal and strategy would be able build great conversational services using existing backend, or even create the new ones.